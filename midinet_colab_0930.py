# -*- coding: utf-8 -*-
"""MidiNet_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-8pUuY6HzekB6MrOHC5hiLDpYTo5scUm
"""

!pip install tensorflow matplotlib

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from sklearn.utils import shuffle

!pip install mido pretty_midi

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
import pretty_midi
import pandas as pd
from typing import Optional

# MIDI 파일을 피아노 롤로 변환하는 함수
def midi_to_piano_roll(midi_path, fs=16):
    midi_data = pretty_midi.PrettyMIDI(midi_path)
    piano_roll = midi_data.get_piano_roll(fs=fs)
    piano_roll = np.clip(piano_roll, 0, 1)
    piano_roll = piano_roll.T / np.max(piano_roll)  # 스케일링 추가
    return piano_roll

# 피아노 롤을 MIDI 파일로 변환하고 저장하는 함수
def notes_to_midi(
    notes: pd.DataFrame,
    out_file: str,
    instrument_name: str,
    velocity: int = 100,  # note loudness
) -> pretty_midi.PrettyMIDI:

    pm = pretty_midi.PrettyMIDI()
    instrument = pretty_midi.Instrument(
        program=pretty_midi.instrument_name_to_program(
            instrument_name))

    prev_start = 0
    for i, note in notes.iterrows():
        start = float(prev_start + note['start'])
        end = float(start + (note['end'] - note['start']))
        midi_note = pretty_midi.Note(
            velocity=velocity,
            pitch=int(note['pitch']),
            start=start,
            end=end,
        )
        instrument.notes.append(midi_note)
        prev_start = start

    pm.instruments.append(instrument)
    pm.write(out_file)
    print(f"Saved generated MIDI: {out_file}")
    return pm

# 피아노 롤 시각화 함수
def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None, title: str = "Piano Roll"):
    """
    피아노 롤을 시각화하는 함수입니다.

    :param notes: pd.DataFrame, 'pitch', 'start', 'end' 컬럼을 포함하는 데이터프레임
    :param count: Optional[int], 시각화할 노트의 개수 (기본값은 None)
    :param title: str, 그래프의 제목
    """
    if count:
        title = f'First {count} notes'
    else:
        title = f'Whole track'
        count = len(notes['pitch'])
    plt.figure(figsize=(20, 4))
    plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)
    plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)
    plt.plot(
        plot_start_stop[:, :count], plot_pitch[:, :count], color="b", marker=".")
    plt.xlabel('Time [s]')
    plt.ylabel('Pitch')
    _ = plt.title(title)
    plt.show()

# 손실 값 시각화 함수
def plot_loss(d_losses, g_losses):
    plt.figure(figsize=(10, 5))
    plt.plot(d_losses, label='Discriminator Loss')
    plt.plot(g_losses, label='Generator Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training Loss')
    plt.legend()
    plt.grid(True)
    plt.show()

# Optimizer를 설정하는 함수
def build_optimizer():
    initial_learning_rate = 0.0002
    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=initial_learning_rate,
        decay_steps=10000,
        decay_rate=0.9)
    return tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5)

# MidiNet 모델 정의
class MidiNet(tf.keras.Model):
    def __init__(self, batch_size=72, output_w=32, output_h=128, y_dim=10, prev_dim=1, z_dim=100, gf_dim=64, df_dim=64,
                 gfc_dim=1024, dfc_dim=1024, c_dim=1):
        super(MidiNet, self).__init__()
        self.batch_size = batch_size
        self.output_w = output_w  # 더 긴 출력 길이
        self.output_h = output_h
        self.y_dim = y_dim
        self.prev_dim = prev_dim
        self.z_dim = z_dim
        self.gf_dim = gf_dim
        self.df_dim = df_dim
        self.gfc_dim = gfc_dim
        self.dfc_dim = dfc_dim
        self.c_dim = c_dim

        self.build_model()

    def build_model(self):
        self.g_prev_bn = [tf.keras.layers.BatchNormalization() for _ in range(4)]
        self.g_bn = [tf.keras.layers.BatchNormalization() for _ in range(5)]
        self.d_bn = [tf.keras.layers.BatchNormalization() for _ in range(3)]

        self.d_optimizer = build_optimizer()
        self.g_optimizer = build_optimizer()

    def generator(self, z, y, prev_x):
        h0_prev = tf.keras.layers.LeakyReLU()(self.g_prev_bn[0](tf.keras.layers.Conv2D(16, (1, 128), strides=(1, 2), padding='same')(prev_x)))
        h1_prev = tf.keras.layers.LeakyReLU()(self.g_prev_bn[1](tf.keras.layers.Conv2D(16, (2, 1), padding='same')(h0_prev)))
        h2_prev = tf.keras.layers.LeakyReLU()(self.g_prev_bn[2](tf.keras.layers.Conv2D(16, (2, 1), padding='same')(h1_prev)))
        h3_prev = tf.keras.layers.LeakyReLU()(self.g_prev_bn[3](tf.keras.layers.Conv2D(16, (2, 1), padding='same')(h2_prev)))

        y = tf.cast(y, tf.float32)
        yb = tf.reshape(y, [self.batch_size, 1, 1, self.y_dim])
        z = tf.concat([z, y], axis=-1)

        h0 = tf.keras.layers.Dense(1024)(z)
        h0 = tf.concat([h0, y], axis=-1)
        h1 = tf.keras.layers.Dense(self.gf_dim * 2 * 2 * 1)(h0)

        h1 = tf.keras.layers.Reshape((2, 1, self.gf_dim * 2))(h1)
        yb_h1 = tf.tile(yb, [1, h1.shape[1], h1.shape[2], 1])
        h1 = tf.concat([h1, yb_h1, tf.image.resize(h3_prev, (h1.shape[1], h1.shape[2]))], axis=-1)

        h2 = tf.keras.layers.LeakyReLU()(self.g_bn[2](tf.keras.layers.Conv2DTranspose(self.gf_dim * 2, (2, 1), strides=(2, 2), padding='same')(h1)))
        yb_h2 = tf.tile(yb, [1, h2.shape[1], h2.shape[2], 1])
        h2 = tf.concat([h2, yb_h2, tf.image.resize(h2_prev, (h2.shape[1], h2.shape[2]))], axis=-1)

        h3 = tf.keras.layers.LeakyReLU()(self.g_bn[3](tf.keras.layers.Conv2DTranspose(self.gf_dim * 2, (2, 1), strides=(2, 2), padding='same')(h2)))
        yb_h3 = tf.tile(yb, [1, h3.shape[1], h3.shape[2], 1])
        h3 = tf.concat([h3, yb_h3, tf.image.resize(h1_prev, (h3.shape[1], h3.shape[2]))], axis=-1)

        h4 = tf.keras.layers.LeakyReLU()(self.g_bn[4](tf.keras.layers.Conv2DTranspose(self.gf_dim * 2, (2, 1), strides=(2, 2), padding='same')(h3)))
        yb_h4 = tf.tile(yb, [1, h4.shape[1], h4.shape[2], 1])
        h4 = tf.concat([h4, yb_h4, tf.image.resize(h0_prev, (h4.shape[1], h4.shape[2]))], axis=-1)

        return tf.keras.layers.Conv2DTranspose(self.c_dim, (1, 128), strides=(1, 2), activation='sigmoid', padding='same')(h4)

    def discriminator(self, x, y):
        y = tf.cast(y, tf.float32)
        yb = tf.reshape(y, [self.batch_size, 1, 1, self.y_dim])
        yb_x = tf.tile(yb, [1, x.shape[1], x.shape[2], 1])
        x = tf.concat([x, yb_x], axis=-1)
        h0 = tf.keras.layers.LeakyReLU()(tf.keras.layers.Conv2D(self.c_dim + self.y_dim, (2, 128), padding='same')(x))
        h0 = tf.concat([h0, yb_x], axis=-1)
        fm = h0
        h1 = tf.keras.layers.LeakyReLU()(self.d_bn[1](tf.keras.layers.Conv2D(self.df_dim + self.y_dim, (4, 1), padding='same')(h0)))
        h1 = tf.keras.layers.Flatten()(h1)
        h1 = tf.concat([h1, y], axis=-1)
        h2 = tf.keras.layers.LeakyReLU()(self.d_bn[2](tf.keras.layers.Dense(self.dfc_dim)(h1)))
        h2 = tf.concat([h2, y], axis=-1)
        h3 = tf.keras.layers.Dense(1)(h2)
        return tf.nn.sigmoid(h3), h3, fm

    def train_step(self, images, prev_images, labels, batch_z):
        with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:
            G = self.generator(batch_z, labels, prev_images)
            D_real, D_logits_real, _ = self.discriminator(images, labels)
            D_fake, D_logits_fake, _ = self.discriminator(G, labels)

            d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_real, labels=0.9 * tf.ones_like(D_real)))
            d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake, labels=tf.zeros_like(D_fake)))
            d_loss = d_loss_real + d_loss_fake

            g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake, labels=tf.ones_like(D_fake)))

        d_gradients = d_tape.gradient(d_loss, self.trainable_variables)
        g_gradients = g_tape.gradient(g_loss, self.trainable_variables)
        self.d_optimizer.apply_gradients(zip(d_gradients, self.trainable_variables))
        self.g_optimizer.apply_gradients(zip(g_gradients, self.trainable_variables))

        return d_loss, g_loss, G

# MIDI 파일을 불러와서 피아노 롤로 변환
midi_path = '/content/FlyMeToTheMoon.mid'  # MIDI 파일 경로
piano_roll = midi_to_piano_roll(midi_path)

# 훈련 데이터를 위한 전처리
# 정확히 (16, 128)의 배수로 자르기
target_shape = 16 * 128  # 리쉐이프하려는 목표 크기
length = (piano_roll.shape[0] // target_shape) * target_shape  # 정확한 배수로 자르기
piano_roll = piano_roll[:length]  # 데이터를 정확한 크기로 자르기

# prev_X와 data_X 생성
prev_X = piano_roll.reshape(-1, 16, 128, 1)[:-1]
data_X = piano_roll.reshape(-1, 16, 128, 1)[1:]

# 레이블을 0으로 채우기
data_y = np.zeros((data_X.shape[0], 10), dtype=np.float32)  # 레이블을 0으로 채움

# 데이터 섞기
data_X, prev_X, data_y = shuffle(data_X, prev_X, data_y, random_state=0)

# 훈련 설정
batch_size = 72
epochs = 51
batch_idxs = len(data_X) // batch_size

# 모델 인스턴스 생성
model = MidiNet()

# 샘플 입력 생성
sample_z = np.random.normal(0, 1, (batch_size, model.z_dim)).astype(np.float32)
sample_prev = prev_X[:batch_size]
sample_labels = data_y[:batch_size]

# 손실 값 기록을 위한 리스트
d_losses = []
g_losses = []

# 훈련 루프
for epoch in range(epochs):
    epoch_d_loss = 0
    epoch_g_loss = 0

    for idx in range(0, batch_idxs):
        batch_images = data_X[idx * batch_size:(idx + 1) * batch_size]
        prev_batch_images = prev_X[idx * batch_size:(idx + 1) * batch_size]
        batch_labels = data_y[idx * batch_size:(idx + 1) * batch_size]
        batch_z = np.random.normal(0, 1, [batch_size, model.z_dim]).astype(np.float32)

        d_loss, g_loss, _ = model.train_step(batch_images, prev_batch_images, batch_labels, batch_z)

        # 학습 과정 확인
        if idx % 10 == 0:
            print(f"Epoch: [{epoch + 1}/{epochs}], Step: [{idx}/{batch_idxs}], D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}")

        epoch_d_loss += d_loss
        epoch_g_loss += g_loss

    # 에포크당 평균 손실 계산
    d_losses.append(epoch_d_loss / batch_idxs)
    g_losses.append(epoch_g_loss / batch_idxs)

    # 각 에포크마다 생성된 샘플
    generated_samples = model.generator(sample_z, sample_labels, sample_prev)
    generated_samples = generated_samples.numpy()

    # 피아노 롤 데이터를 pandas DataFrame 형태로 변환
    # 예시로 생성된 데이터 사용
    notes_df = pd.DataFrame({
        'pitch': np.random.randint(60, 80, size=200),  # 피치 값
        'start': np.linspace(0, 50, 200),  # 노트 시작 시간
        'end': np.linspace(1, 51, 200)  # 노트 끝 시간
    })

    # 시각화할 샘플 수를 생성된 샘플 수에 맞추기
    num_samples_to_visualize = min(len(generated_samples), 5)  # 생성된 샘플 수에 맞춰 조정

    # 피아노 롤 시각화
    for i in range(num_samples_to_visualize):
        plot_piano_roll(notes_df, title=f'Epoch {epoch + 1} - Sample {i + 1}')

    print(f"Epoch: [{epoch + 1}/{epochs}], D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}")

    # 손실 함수 값 시각화


    # 생성된 샘플을 MIDI 파일로 저장
    if epoch % 10 == 0:  # 10 에포크마다 저장
        for i, extended_sample in enumerate(generated_samples[:num_samples_to_visualize]):  # 생성된 샘플 수만큼 저장
            # 피아노 롤의 채널(마지막 차원)이 있는 경우, 채널을 제거해야 함
            extended_sample_2d = extended_sample[:, :, 0] if extended_sample.ndim == 3 else extended_sample

            # 새로운 데이터프레임으로 변환
            notes_df = pd.DataFrame({
                'pitch': np.random.randint(60, 80, size=extended_sample_2d.shape[0]),  # 피치 값
                'start': np.linspace(0, 50, extended_sample_2d.shape[0]),  # 노트 시작 시간
                'end': np.linspace(1, 51, extended_sample_2d.shape[0])  # 노트 끝 시간
            })

            midi_filename = f'/content/Test_epoch_{epoch + 1}_sample_{i + 1}.mid'
            notes_to_midi(notes_df, midi_filename, instrument_name='Acoustic Grand Piano', velocity=100)  # 새로운 함수 사용

plot_loss(d_losses, g_losses)

