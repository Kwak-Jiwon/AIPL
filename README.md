# AIPL


## 👨‍🏫 Project Overview
This project aims to develop a system that generates music using MIDI files and creates melodies based on user-input lyrics through TTS (Text-to-Speech) technology. The core technologies used in this project are Midinet and Tacotron. MIDI files are essential in digital music as they contain information about rhythm, harmony, and melody. In this project, we leverage Midinet to analyze MIDI data and develop an algorithm that can automatically generate new music.

When a user inputs lyrics, the system uses Tacotron to synthesize speech. Tacotron is a state-of-the-art TTS model that excels at generating natural-sounding speech, playing a key role in creating melodies that harmonize with the generated MIDI music. The system matches the rhythm and melody of the lyrics with the MIDI music, producing a seamless blend between the two.

## ⏲️ Development Period 
- 2024-09-01 - present.

  
## 🧑‍🤝‍🧑 Developer Information
- [Ji-eun Seo](https://github.com/Nick-Stokes)
- [Ji-won Kwak](https://github.com/Kwak-Jiwon)
- [Ji-min Kim](https://github.com/xxjimin)

<img width="80%" src="https://github.com/user-attachments/assets/d4f4bf4b-0ce6-4452-ba38-2d437aa183f4"/>
<img width="80%" src="https://github.com/user-attachments/assets/f0ca0060-0af7-4388-8343-d630e5a94f64"/>
